# app.py (ìƒíƒœ ì´ˆê¸°í™” ë²„ê·¸ ìµœì¢… ìˆ˜ì •ë³¸)

from PIL import Image
import nest_asyncio
nest_asyncio.apply()
from streamlit_lottie import st_lottie
import json
import streamlit as st
import os
import shutil
import re
import json
from datetime import datetime
from dotenv import load_dotenv
from langchain_core.messages import AIMessage, HumanMessage
import rag_core
from config import DOCS_DIR, KNOWLEDGE_BASE_DIR, SYSTEM_PROMPTS,LANG_TEXT,CONTEXTUALIZE_Q_PROMPTS

st.set_page_config(layout="wide", page_icon="assets/Project_logo.png")
load_dotenv()
os.makedirs(KNOWLEDGE_BASE_DIR, exist_ok=True)



# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'api_provider' not in st.session_state: st.session_state.api_provider = 'NVIDIA'
if 'language' not in st.session_state: st.session_state.language = 'English'
if "messages" not in st.session_state: st.session_state.messages = []
if "retriever" not in st.session_state: st.session_state.retriever = None
if "selected_kb" not in st.session_state: st.session_state.selected_kb = LANG_TEXT[st.session_state.language]['create_new_kb_option']
if "user_api_key" not in st.session_state: st.session_state.user_api_key = ""


lang = LANG_TEXT[st.session_state.language]
create_new_kb_option = lang['create_new_kb_option']
system_prompt = SYSTEM_PROMPTS[st.session_state.language]
if "api_key_source" not in st.session_state:
    st.session_state.api_key_source = lang['api_key_source_local']
valid_api_sources = [lang['api_key_source_local'], lang['api_key_source_user']]
if st.session_state.api_key_source not in valid_api_sources:
    st.session_state.api_key_source = lang['api_key_source_local']

# --- í—¬í¼ ë° ì½œë°± í•¨ìˆ˜ ---
def get_knowledge_bases(): return [d for d in os.listdir(KNOWLEDGE_BASE_DIR) if os.path.isdir(os.path.join(KNOWLEDGE_BASE_DIR, d))]
def is_valid_kb_name(name): return re.match("^[A-Za-z0-9_-]+$", name) is not None
def on_change_reset_retriever(): st.session_state.retriever = None
def on_api_provider_change(): st.session_state.retriever = None; st.session_state.user_api_key = ""
def on_language_change(): st.session_state.messages = []
def on_kb_select_change():
    st.session_state.retriever = None
    st.session_state.selected_kb = st.session_state.kb_selector
@st.cache_resource
def get_models(api_provider, user_api_key): return rag_core.load_models(api_provider, user_api_key)
def process_chat_load():
    if 'chat_file_uploader' in st.session_state and st.session_state.chat_file_uploader is not None:
        try:
            loaded_file = st.session_state.chat_file_uploader
            data = json.load(loaded_file)
            
            kb_name_from_file = data.get("knowledge_base")
            messages_from_file = data.get("messages")

            if messages_from_file is None:
                messages_from_file = data if isinstance(data, list) else []

            if not kb_name_from_file or kb_name_from_file not in get_knowledge_bases():
                st.session_state.messages = messages_from_file
                st.warning(f"Chat history loaded, but its Knowledge Base ('{kb_name_from_file}') was not found. Please select a KB manually.")
            else:
                st.session_state.selected_kb = kb_name_from_file
                st.session_state.messages = messages_from_file
                st.session_state.retriever = None
                st.success(f"Chat history and Knowledge Base '{kb_name_from_file}' are being loaded.")
                # ì½œë°± í•¨ìˆ˜ ì•ˆì—ì„œëŠ” st.rerun()ì„ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
        except Exception as e:
            st.error(f"Failed to load or parse chat file: {e}")
@st.cache_data
def load_lottiefile(filepath: str):
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return None # íŒŒì¼ì´ ì—†ìœ¼ë©´ Noneì„ ë°˜í™˜

# ================================== 1. í™€ (ì‚¬ì´ë“œë°”) ==================================
with st.sidebar:
    # (ë¡œê³ , ì–¸ì–´, AI ì œê³µì‚¬, API í‚¤ UI ë¶€ë¶„ì€ ë™ì¼)
    try:
        logo_path = "assets/Project_logo.png"
        if os.path.exists(logo_path): st.image(Image.open(logo_path),width=200)
        else: st.error("Logo file not found.")
    except Exception as e: st.error(f"Error loading logo: {e}")
    st.subheader(lang['settings_header'])
    lang_options_value = ['English', 'Korean']
    current_lang_index = lang_options_value.index(st.session_state.language)
    selected_language = st.selectbox(
        label=lang['lang_select_label'], options=lang_options_value, index=current_lang_index,
        format_func=lambda value: "English" if value == 'English' else "Korean",
        on_change=on_language_change
    )
    if selected_language != st.session_state.language:
        st.session_state.language = selected_language
        st.rerun()
    
    api_options = ['NVIDIA', 'Google']
    api_index = api_options.index(st.session_state.api_provider)
    selected_api = st.selectbox(lang['api_select_label'], api_options, index=api_index, on_change=on_api_provider_change)
    if selected_api != st.session_state.api_provider:
        st.session_state.api_provider = selected_api
        st.rerun()

    if st.session_state.api_provider == 'NVIDIA' and st.session_state.language == 'Korean':
        st.warning(lang['nvidia_korean_warning'])
    st.divider()
    st.subheader(lang['api_key_header'])
    st.radio(lang['api_key_source_label'], [lang['api_key_source_local'], lang['api_key_source_user']], key="api_key_source")
    if st.session_state.api_key_source == lang['api_key_source_user']:
        st.text_input(lang['api_key_label'].format(api_provider=st.session_state.api_provider), type="password", key="user_api_key")
    st.divider()

     # âœ¨ KB ì„ íƒ ë¡œì§ ìˆ˜ì • (ì½œë°± ì œê±°, ë” ì§ê´€ì ì¸ ë°©ì‹ìœ¼ë¡œ)
    kb_options = get_knowledge_bases()
    try:
        kb_index = kb_options.index(st.session_state.selected_kb)
    except ValueError:
        kb_index = 0 # st.session_stateì— ì €ì¥ëœ ê°’ì´ ëª©ë¡ì— ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ

    selected_kb_from_ui = st.selectbox(lang['kb_select_label'], options=kb_options, index=kb_index)

    # UIì—ì„œ ì„ íƒëœ ê°’ê³¼ session_stateì— ì €ì¥ëœ ê°’ì´ ë‹¤ë¥¼ ë•Œë§Œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  rerun
    if selected_kb_from_ui != st.session_state.selected_kb:
        st.session_state.selected_kb = selected_kb_from_ui
        st.session_state.retriever = None # ë¦¬íŠ¸ë¦¬ë²„ ë¦¬ì…‹
        st.rerun()
   

    # KB ê´€ë¦¬ UI
    if st.session_state.selected_kb == create_new_kb_option:
        st.subheader(lang['new_kb_header'])
        with st.form("new_kb_form"):
            new_kb_name = st.text_input(lang['new_kb_name_label'], help=lang['new_kb_name_help'])
            uploaded_files = st.file_uploader(lang['upload_label'], accept_multiple_files=True)
            submitted = st.form_submit_button(lang['create_button'])
    elif st.session_state.selected_kb != create_new_kb_option:
        st.subheader(lang['update_kb_header'])
        with st.form("update_kb_form"):
            update_files = st.file_uploader(lang['update_upload_label'], accept_multiple_files=True)
            update_submitted = st.form_submit_button(lang['update_button'])
        st.divider()
        if st.button(lang['kb_reset_button']):
            shutil.rmtree(os.path.join(KNOWLEDGE_BASE_DIR, st.session_state.selected_kb))
            st.success(lang['kb_reset_success'].format(kb_name=st.session_state.selected_kb))
            st.session_state.selected_kb = create_new_kb_option
            st.rerun()
    st.divider()
    
    # ì±„íŒ… ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° UI
    st.subheader(lang['chat_history_header'])
    now = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    file_name = f"chat_history_{now}.json"
    
    chat_data_to_save = {
        "knowledge_base": st.session_state.selected_kb if st.session_state.selected_kb != create_new_kb_option else None,
        "messages": st.session_state.messages
    }
    chat_history_json = json.dumps(chat_data_to_save, indent=2, ensure_ascii=False)
    st.download_button(
        label=lang['chat_history_save_button'], 
        data=chat_history_json, 
        file_name=file_name, 
        mime="application/json",
        key="download_btn" # âœ¨ ì•ˆì •ì„±ì„ ìœ„í•´ key ì¶”ê°€
    )
    # âœ¨ 2. íŒŒì¼ ì—…ë¡œë”ì— keyì™€ on_change ì½œë°±ì„ ì—°ê²°í•©ë‹ˆë‹¤.
    st.file_uploader(
        label=lang['chat_history_load_label'], 
        type=['json'], 
        key='chat_file_uploader', # ìœ„ì ¯ì˜ ìƒíƒœë¥¼ ì°¸ì¡°í•˜ê¸° ìœ„í•œ key
        on_change=process_chat_load # íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ì´ í•¨ìˆ˜ë¥¼ ì‹¤í–‰
    )
# ================================== 2. ì£¼ë°© (ë©”ì¸ ë¡œì§) ==================================
final_api_key = None
if st.session_state.api_key_source == lang['api_key_source_local']:
    try: final_api_key = st.secrets[f"{st.session_state.api_provider.upper()}_API_KEY"]
    except: final_api_key = os.getenv(f"{st.session_state.api_provider.upper()}_API_KEY")
else: final_api_key = st.session_state.user_api_key

llm, embedder = get_models(st.session_state.api_provider, final_api_key)
api_key_ok = llm is not None

if api_key_ok:
    if 'submitted' in locals() and submitted:
        if not new_kb_name or not is_valid_kb_name(new_kb_name): st.error(lang['invalid_kb_name_error'])
        elif not uploaded_files: st.warning("Please upload files.")
        else:
            if os.path.exists(DOCS_DIR): shutil.rmtree(DOCS_DIR)
            os.makedirs(DOCS_DIR)
            for file in uploaded_files:
                with open(os.path.join(DOCS_DIR, file.name), "wb") as f: f.write(file.read())
            with st.spinner(lang['creating_db'].format(kb_name=new_kb_name)):
                rag_core.create_and_save_retriever(embedder, new_kb_name)
                st.success(lang['db_created_success'].format(kb_name=new_kb_name))
                st.session_state.selected_kb = new_kb_name; st.rerun()
    if 'update_submitted' in locals() and update_submitted:
        if not update_files: st.warning("Please upload files to add.")
        else:
            if os.path.exists(DOCS_DIR): shutil.rmtree(DOCS_DIR)
            os.makedirs(DOCS_DIR)
            for file in update_files:
                with open(os.path.join(DOCS_DIR, file.name), "wb") as f: f.write(file.read())
            with st.spinner(lang['updating_db'].format(kb_name=st.session_state.selected_kb)):
                st.session_state.retriever = rag_core.update_and_save_retriever(embedder, st.session_state.selected_kb)
                st.success(lang['db_updated_success'].format(kb_name=st.session_state.selected_kb))
            if os.path.exists(DOCS_DIR): shutil.rmtree(DOCS_DIR)
    if st.session_state.retriever is None and st.session_state.selected_kb != create_new_kb_option:
        with st.spinner(f"Loading '{st.session_state.selected_kb}'..."):
            st.session_state.retriever = rag_core.load_retriever(embedder, st.session_state.selected_kb)
        if st.session_state.retriever: st.sidebar.success(f"'{st.session_state.selected_kb}' loaded.")


final_page_title = lang['page_title']
# --- ì‹œì—°ìš© íŠ¹ìˆ˜ ê¸°ëŠ¥: ì´ë¯¸ì§€ ë¶„ì„ (Gemini Vision Demo) ì„¹ì…˜ ---
if st.session_state.api_provider == 'Google':
    # lang ë”•ì…”ë„ˆë¦¬ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜´
    # st.write(DEMO_VISION_PROMPTS)
   with st.expander(lang['vision_expander_title']):

    # ë¶„ì„ ëª¨ë“œ UI ì´ë¦„ê³¼ LANG_TEXT ë‚´ë¶€ì˜ í”„ë¡¬í”„íŠ¸ í‚¤ ë§¤í•‘
    vision_mode_mapping = {
        "Smart Analysis (Vision + RAG)": "vision_prompt_smart_analysis",
        "TOEIC Grammar Expert (EE-Assistant)": "vision_prompt_toeic_expert",
        "Electrical/Electronic Engineering Problem Solver (EE-Assistant)": "vision_prompt_ee_problem_solver",
        "Image Content Describer (General Purpose)": "vision_prompt_image_describer"
    }

    # 1. ë¶„ì„ ëª¨ë“œ ì„ íƒ
    selected_scenario_display_name = st.selectbox(
        lang['vision_select_mode_label'],
        options=list(vision_mode_mapping.keys()),
        key="vision_scenario_selection"
    )
    selected_scenario_key = vision_mode_mapping[selected_scenario_display_name]

    # 2. ì´ë¯¸ì§€ ì†ŒìŠ¤ ì„ íƒ
    vision_input_mode = st.radio(
        lang['vision_input_mode_label'],
        (lang['vision_input_mode_upload'], lang['vision_input_mode_url']),
        key="vision_input_mode",
        horizontal=True,
    )

    # 3. UI ë™ì  ë³€ê²½
    uploaded_image = None
    image_url_input = None
    if st.session_state.vision_input_mode == lang['vision_input_mode_upload'] or selected_scenario_display_name == "Smart Analysis (Vision + RAG)":
        if selected_scenario_display_name == "Smart Analysis (Vision + RAG)":
            st.info(lang['vision_smart_analysis_info'])
        
        uploaded_image = st.file_uploader(
            lang['vision_upload_image_label'],
            type=['png', 'jpg', 'jpeg'],
            key="vision_file_uploader"
        )
    else:
        image_url_input = st.text_input(
            lang['vision_url_input_label'],
            placeholder=lang['vision_url_input_placeholder']
        )

    # 4. ì§ˆë¬¸ ì…ë ¥
    image_question = st.text_input(
        lang['vision_question_input_label'],
        placeholder=lang['vision_question_placeholder']
    )

    # 5. ë¶„ì„ ì‹œì‘ ë²„íŠ¼ ë¡œì§
    if st.button(lang['vision_analyze_button_label']):

    
        is_input_ready = (uploaded_image or image_url_input) and image_question and api_key_ok

        if is_input_ready:
            selected_prompt_content = lang[selected_scenario_key]
            
            image_for_session = f"data:{uploaded_image.type};base64,{rag_core.image_to_base64(uploaded_image)}"if uploaded_image else image_url_input
            
            user_request_source = f"via File: {uploaded_image.name}" if uploaded_image else "via URL"
            st.session_state.messages.append({
                "role": "user",
                "content": f"Image Analysis Request ({user_request_source}): {image_question}",
                "image": image_for_session
            })
            
            with st.chat_message("user"):
                st.markdown(f"**Image Analysis Request:**\n\n- Mode: *{selected_scenario_display_name}*\n- Question: *{image_question}*")
                st.image(image_for_session, width=300)

            with st.chat_message("assistant"):
                # --- ğŸš¨ ìˆ˜ì •: ë‹µë³€ ìƒì„± ë¡œì§ ë‹¨ìˆœí™” ---
                full_response = ""
                sources = []
                
                with st.spinner("EE-Assistant is thinking..."): # ë‹¨ìˆœí•œ ìŠ¤í”¼ë„ˆë¡œ ë³€ê²½
                    responses = None
                    
                    if selected_scenario_display_name == "Smart Analysis (Vision + RAG)":
                        if not st.session_state.retriever:
                            full_response = "Smart Analysis requires a Knowledge Base."
                        elif not uploaded_image:
                            full_response = "Smart Analysis only supports 'File Upload'."
                        else:
                            responses = rag_core.get_fused_vision_rag_response(
                                llm=llm, retriever=st.session_state.retriever,
                                image_file=uploaded_image, question=image_question,
                                system_prompt=selected_prompt_content
                            )
                    else: # ì¼ë°˜ Vision ëª¨ë“œ
                        if uploaded_image:
                            responses = rag_core.get_response_with_vision_from_file(
                                llm=llm, image_file=uploaded_image,
                                question=image_question, system_prompt=selected_prompt_content
                            )
                        else:
                            responses = rag_core.get_response_with_vision_from_url(
                                llm=llm, image_url=image_url_input,
                                question=image_question, system_prompt=selected_prompt_content
                            )
                    
                    if responses:
                        for response in responses:
                            if "sources" in response:
                                sources.extend(response["sources"])
                            elif "chunk" in response:
                                full_response += response['chunk'].content
                            elif hasattr(response, 'content'): # í•˜ìœ„ í˜¸í™˜
                                full_response += response.content

                # --- ë£¨í”„ê°€ ëë‚œ í›„, ì™„ì„±ëœ ë‚´ìš©ì„ í•œ ë²ˆì— í‘œì‹œ ---
                st.markdown(full_response)
                if sources:
                    with st.expander("ì°¸ê³  ìë£Œ (Source Documents)"):
                        for source in sources:
                            st.write(f"- {source}")
                
                st.session_state.messages.append({"role": "assistant", "content": full_response})
        
        elif not api_key_ok:
            st.error(lang['vision_api_key_error_message'])
        else:
            st.warning(lang['vision_missing_input_warning'])
st.subheader(final_page_title)
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "image" in message and message["image"]:
            st.image(message["image"], width=300)

if not api_key_ok: st.info(lang['api_key_missing_error'])
elif not st.session_state.retriever: st.info(lang['Knowledge_Base_Select'])
# app.py íŒŒì¼ í•˜ë‹¨, ì¼ë°˜ RAG ì±„íŒ… ë¡œì§ (else: ë¸”ë¡ ì „ì²´)

else:
    # í˜„ì¬ ì–¸ì–´ ì„¤ì •ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ê°ê° ê°€ì ¸ì˜µë‹ˆë‹¤.
    system_prompt = SYSTEM_PROMPTS[st.session_state.language]
    contextualize_q_prompt_str = CONTEXTUALIZE_Q_PROMPTS[st.session_state.language]
    # âœ¨ --- ì˜¬ë°”ë¥¸ ë””ë²„ê¹… ì½”ë“œ ì‹œì‘ --- âœ¨
    
    # # 1. rag_coreì—ì„œ í–ˆë˜ ê²ƒê³¼ ë˜‘ê°™ì´, ì§ˆë¬¸ ì¬êµ¬ì„±ê¸°('history_aware_retriever')ë¥¼ ì§ì ‘ ìƒì„±í•©ë‹ˆë‹¤.
    # #    (rag_coreì™€ langchain.chainsì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ì„ import í•´ì•¼ í•©ë‹ˆë‹¤)
    # from langchain.chains import create_history_aware_retriever
    # from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

    # contextualize_q_prompt = ChatPromptTemplate.from_messages([
    #     ("system", contextualize_q_prompt_str),
    #     MessagesPlaceholder("chat_history"),
    #     ("human", "{input}"),
    # ])
    # history_aware_retriever = create_history_aware_retriever(
    #     llm, st.session_state.retriever, contextualize_q_prompt
    #)
    # âœ¨ --- ì˜¬ë°”ë¥¸ ë””ë²„ê¹… ì½”ë“œ ë --- âœ¨

    # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ LangChainì´ ì´í•´í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜
    chat_history_for_chain = [HumanMessage(content=msg["content"]) if msg["role"] == "user" else AIMessage(content=msg["content"]) for msg in st.session_state.messages[:-1]]
    
    # ëŒ€í™”í˜• RAG ì²´ì¸ ìƒì„±
    conversational_rag_chain = rag_core.create_conversational_rag_chain(llm, st.session_state.retriever, SYSTEM_PROMPTS[st.session_state.language],contextualize_q_prompt_str )

    user_input = st.chat_input(lang['chat_placeholder'])
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        
        # âœ¨ --- ë””ë²„ê¹… ì¶œë ¥ ì½”ë“œ ì‹œì‘ --- âœ¨
        # 1. ìœ„ì—ì„œ ë§Œë“  ì¬êµ¬ì„±ê¸°ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
        #    ì´ê²ƒì´ ì‹¤ì œë¡œ RAG ê²€ìƒ‰ì— ì‚¬ìš©ë  'ì¬êµ¬ì„±ëœ ì§ˆë¬¸'ì…ë‹ˆë‹¤.
        # rephrased_question_docs = history_aware_retriever.invoke({
        #     "chat_history": chat_history_for_chain,
        #     "input": user_input
        # })
        # # 2. í„°ë¯¸ë„(ì½˜ì†”)ì— ì¬êµ¬ì„±ëœ ì§ˆë¬¸ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        # #    history_aware_retrieverëŠ” ë¬¸ì„œ(Document) ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        # print("==============================================")
        # print(f"ğŸ‘¤ ì›ë³¸ ì§ˆë¬¸: {user_input}")
        # print(f"ğŸ¤– ì¬êµ¬ì„± í›„ ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(rephrased_question_docs)}")
        # print("ğŸ“ ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© (ì¬êµ¬ì„±ëœ ì§ˆë¬¸ì˜ ê²°ê³¼):")
        # for i, doc in enumerate(rephrased_question_docs):
        #     print(f"--- ë¬¸ì„œ {i+1} ---\n{doc.page_content}\n")
        # print("==============================================")
        # # âœ¨ --- ë””ë²„ê¹… ì¶œë ¥ ì½”ë“œ ë --- âœ¨
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            LOTTIE_FILE_PATH = "UI_Animation/Material wave loading.json"
            message_placeholder = st.empty()

            # 1. ëª¨ë“  ìš”ì†Œ(Lottie, í…ìŠ¤íŠ¸, ìµœì¢… ë‹µë³€)ê°€ ê·¸ë ¤ì§ˆ ë‹¨ í•˜ë‚˜ì˜ placeholderë¥¼ ë§Œë“­ë‹ˆë‹¤.
           
            # âœ¨ --- Thinking ì• ë‹ˆë©”ì´ì…˜ ë¡œì§ ì‹œì‘ --- âœ¨
            try:
                # 2. ë¡œì»¬ Lottie íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤. (ê²½ë¡œ í™•ì¸ í•„ìˆ˜)
                #    ì´ ë¡œì§ì€ ë§¤ë²ˆ ì‹¤í–‰ë˜ë¯€ë¡œ, íŒŒì¼ ë¡œë“œ í•¨ìˆ˜ ìœ„ì— @st.cache_dataë¥¼ ë¶™ì´ëŠ” ê²ƒì´ ì„±ëŠ¥ì— ì¢‹ìŠµë‹ˆë‹¤.
                lottie_thinking_json = load_lottiefile("UI_Animation/Material wave loading.json")
                
                # 3. placeholder ì•ˆì— containerë¥¼ ë§Œë“¤ê³ , ê·¸ ì•ˆì— ì»¬ëŸ¼ê³¼ ëª¨ë“  ìš”ì†Œë¥¼ ë°°ì¹˜í•©ë‹ˆë‹¤.
                with message_placeholder.container():
                    col1, col2 = st.columns([1, 6.3]) # ì°¾ìœ¼ì‹  ìµœì ì˜ ë¹„ìœ¨
                    
                    with col1:
                        st_lottie(
                            lottie_thinking_json,
                            height=130,
                            width=80,
                            quality='medium',
                            key="thinking" # keyëŠ” ê°„ë‹¨í•˜ê²Œ í•˜ë‚˜ë§Œ ì§€ì •
                        )
                    

            except FileNotFoundError:
                # Lottie íŒŒì¼ì„ ì°¾ì§€ ëª»í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜ˆì™¸ ì²˜ë¦¬
                message_placeholder.markdown("EE-Assistant is thinking... â–Œ")
            except Exception as e:
                # ê¸°íƒ€ Lottie ê´€ë ¨ ì—ëŸ¬ ë°œìƒ ì‹œ
                print(f"Lottie Error: {e}")
                message_placeholder.markdown("EE-Assistant is thinking... â–Œ")
            # âœ¨ --- Thinking ì• ë‹ˆë©”ì´ì…˜ ë¡œì§ ë --- âœ¨
            

            # 2. ì†ŒìŠ¤(ì°¸ê³  ìë£Œ)ê°€ í‘œì‹œë  expanderë¥¼ ë¯¸ë¦¬ ë§Œë“­ë‹ˆë‹¤. (ë‚´ìš©ì€ ë¹„ì–´ìˆìŒ)
            source_expander = st.expander("ì°¸ê³  ìë£Œ (Source Documents)")
            source_container = source_expander.container() # expander ë‚´ë¶€ì— ì»¨í…ì¸ ë¥¼ ì¶”ê°€í•  ì»¨í…Œì´ë„ˆ
            
            full_response = ""
            
            # 3. ìŠ¤í”¼ë„ˆëŠ” ì´ì œ ë‹µë³€ ìƒì„± 'ê³¼ì • ì „ì²´'ê°€ ì•„ë‹ˆë¼, 'ì²« ì‘ë‹µì´ ì˜¤ê¸° ì „ê¹Œì§€'ë§Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
            #    ì—¬ê¸°ì„œëŠ” ìŠ¤í”¼ë„ˆë¥¼ ì œê±°í•˜ê³ , placeholderì— ì§ì ‘ ìƒíƒœë¥¼ í‘œì‹œí•˜ëŠ” ê²ƒì´ ë” ì¢‹ìŠµë‹ˆë‹¤.
            # message_placeholder.markdown("EE-Assistant is thinking... :thinking:") # replaced with lottie anime 

            # 4. rag_coreì—ì„œ ë‹µë³€ê³¼ ì†ŒìŠ¤ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë°›ì•„ì˜µë‹ˆë‹¤.
            responses = rag_core.get_response(user_input, chat_history_for_chain, conversational_rag_chain)
            
            sources_processed = False
            for response in responses:
                # 5. ì†ŒìŠ¤ ì²˜ë¦¬ (ë‹¨ í•œ ë²ˆë§Œ ì‹¤í–‰)
                if "sources" in response and not sources_processed:
                    with source_container:
                        for source in set(response["sources"]): # ì¤‘ë³µ ì œê±°
                            st.write(f"- {source}")
                    sources_processed = True # í”Œë˜ê·¸ë¥¼ ì„¤ì •í•˜ì—¬ ë‹¤ì‹œëŠ” ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ í•¨

                # 6. ë‹µë³€ ì¡°ê° ì²˜ë¦¬
                if "chunk" in response:
                    full_response += response["chunk"]
                    message_placeholder.markdown(full_response + "â–Œ")

            # 7. ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚˜ë©´ ì»¤ì„œ(â–Œ)ë¥¼ ì œê±°í•œ ìµœì¢…ë³¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.
            message_placeholder.markdown(full_response)
            
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            # --- âœ¨ ê°œì„ ëœ ë¡œì§ ë ---
